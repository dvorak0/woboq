<inh f='ceres-solver/include/ceres/loss_function.h' l='86' c='ceres::LossFunction'/>
<def f='ceres-solver/include/ceres/loss_function.h' l='175' ll='184'/>
<size>24</size>
<doc f='ceres-solver/include/ceres/loss_function.h' l='137'>// Scaling
// -------
// Given one robustifier
//   s -&gt; rho(s)
// one can change the length scale at which robustification takes
// place, by adding a scale factor &apos;a&apos; as follows:
//
//   s -&gt; a^2 rho(s / a^2).
//
// The first and second derivatives are:
//
//   s -&gt; rho&apos;(s / a^2),
//   s -&gt; (1 / a^2) rho&apos;&apos;(s / a^2),
//
// but the behaviour near s = 0 is the same as the original function,
// i.e.
//
//   rho(s) = s + higher order terms,
//   a^2 rho(s / a^2) = s + higher order terms.
//
// The scalar &apos;a&apos; should be positive.
//
// The reason for the appearance of squaring is that &apos;a&apos; is in the
// units of the residual vector norm whereas &apos;s&apos; is a squared
// norm. For applications it is more convenient to specify &apos;a&apos; than
// its square. The commonly used robustifiers below are described in
// un-scaled format (a = 1) but their implementations work for any
// non-zero value of &apos;a&apos;.

// Huber.
//
//   rho(s) = s               for s &lt;= 1,
//   rho(s) = 2 sqrt(s) - 1   for s &gt;= 1.
//
// At s = 0: rho = [0, 1, 0].
//
// The scaling parameter &apos;a&apos; corresponds to &apos;delta&apos; on this page:
//   http://en.wikipedia.org/wiki/Huber_Loss_Function</doc>
<fun r='_ZN5ceres9HuberLossC1Ed'/>
<fun r='_ZNK5ceres9HuberLoss8EvaluateEdPd'/>
<mbr r='ceres::HuberLoss::a_' o='64' t='const double'/>
<mbr r='ceres::HuberLoss::b_' o='128' t='const double'/>
