<def f='codebrowser/gtsam/nonlinear/NonlinearOptimizer.h' l='75' ll='151'/>
<use f='codebrowser/gtsam/nonlinear/NonlinearOptimizer.h' l='84'/>
<ovr f='codebrowser/gtsam/nonlinear/LevenbergMarquardtOptimizer.h' l='35' c='gtsam::LevenbergMarquardtOptimizer'/>
<use f='codebrowser/gtsam/nonlinear/LevenbergMarquardtOptimizer.h' l='35'/>
<size>48</size>
<doc f='codebrowser/gtsam/nonlinear/NonlinearOptimizer.h' l='28'>/**
 * This is the abstract interface for classes that can optimize for the
 * maximum-likelihood estimate of a NonlinearFactorGraph.
 *
 * To use a class derived from this interface, construct the class with a
 * NonlinearFactorGraph and an initial Values variable assignment.  Next, call the
 * optimize() method which returns the optimized variable assignment.
 *
 * Simple and compact example:
 * \code
// One-liner to do full optimization and use the result.
Values result = DoglegOptimizer(graph, initialValues).optimize();
\endcode
 *
 * Example exposing more functionality and details:
 * \code
// Create initial optimizer
DoglegOptimizer optimizer(graph, initialValues);

// Run full optimization until convergence.
Values result = optimizer-&gt;optimize();

// The new optimizer has results and statistics
cout &lt;&lt; &quot;Converged in &quot; &lt;&lt; optimizer.iterations() &lt;&lt; &quot; iterations &quot;
        &quot;with final error &quot; &lt;&lt; optimizer.error() &lt;&lt; endl;
\endcode
 *
 * Example of setting parameters before optimization:
 * \code
// Each derived optimizer type has its own parameters class, which inherits from NonlinearOptimizerParams
DoglegParams params;
params.factorization = DoglegParams::QR;
params.relativeErrorTol = 1e-3;
params.absoluteErrorTol = 1e-3;

// Optimize
Values result = DoglegOptimizer(graph, initialValues, params).optimize();
\endcode
 *
 * This interface also exposes an iterate() method, which performs one
 * iteration.  The optimize() method simply calls iterate() multiple times,
 * until the error changes less than a threshold.  We expose iterate() so that
 * you can easily control what happens between iterations, such as drawing or
 * printing, moving points from behind the camera to in front, etc.
 *
 * For more flexibility you may override virtual methods in your own derived class.
 */</doc>
<mbr r='gtsam::NonlinearOptimizer::graph_' o='64' t='NonlinearFactorGraph'/>
<mbr r='gtsam::NonlinearOptimizer::state_' o='320' t='std::unique_ptr&lt;internal::NonlinearOptimizerState&gt;'/>
<fun r='_ZN5gtsam18NonlinearOptimizer8optimizeEv'/>
<fun r='_ZN5gtsam18NonlinearOptimizer14optimizeSafelyEv'/>
<fun r='_ZNK5gtsam18NonlinearOptimizer5errorEv'/>
<fun r='_ZNK5gtsam18NonlinearOptimizer10iterationsEv'/>
<fun r='_ZNK5gtsam18NonlinearOptimizer6valuesEv'/>
<fun r='_ZNK5gtsam18NonlinearOptimizer5graphEv'/>
<fun r='_ZN5gtsam18NonlinearOptimizerD1Ev'/>
<fun r='_ZNK5gtsam18NonlinearOptimizer5solveERKNS_19GaussianFactorGraphERKNS_24NonlinearOptimizerParamsE'/>
<fun r='_ZN5gtsam18NonlinearOptimizer7iterateEv'/>
<fun r='_ZN5gtsam18NonlinearOptimizer15defaultOptimizeEv'/>
<fun r='_ZNK5gtsam18NonlinearOptimizer7_paramsEv'/>
<fun r='_ZN5gtsam18NonlinearOptimizerC1ERKNS_20NonlinearFactorGraphESt10unique_ptrINS_8internal23NonlinearOptimizerStateESt14default_deleteIS6_EE'/>
<ovr f='codebrowser/gtsam/nonlinear/GaussNewtonOptimizer.h' l='38' c='gtsam::GaussNewtonOptimizer'/>
<use f='codebrowser/gtsam/nonlinear/GaussNewtonOptimizer.h' l='38'/>
<size>48</size>
<ovr f='codebrowser/gtsam/nonlinear/DoglegOptimizer.h' l='68' c='gtsam::DoglegOptimizer'/>
<use f='codebrowser/gtsam/nonlinear/DoglegOptimizer.h' l='68'/>
<size>48</size>
<use f='codebrowser/gtsam/constrained/ConstrainedOptimizer.h' l='87'/>
<size>48</size>
<use f='codebrowser/gtsam/nonlinear/DoglegOptimizer.cpp' l='67' c='_ZN5gtsam15DoglegOptimizerC1ERKNS_20NonlinearFactorGraphERKNS_6ValuesERKNS_12DoglegParamsE'/>
<use f='codebrowser/gtsam/nonlinear/DoglegOptimizer.cpp' l='74' c='_ZN5gtsam15DoglegOptimizerC1ERKNS_20NonlinearFactorGraphERKNS_6ValuesERKNS_8OrderingE'/>
<size>48</size>
<use f='codebrowser/gtsam/nonlinear/GaussNewtonOptimizer.cpp' l='32' c='_ZN5gtsam20GaussNewtonOptimizerC1ERKNS_20NonlinearFactorGraphERKNS_6ValuesERKNS_17GaussNewtonParamsE'/>
<use f='codebrowser/gtsam/nonlinear/GaussNewtonOptimizer.cpp' l='38' c='_ZN5gtsam20GaussNewtonOptimizerC1ERKNS_20NonlinearFactorGraphERKNS_6ValuesERKNS_8OrderingE'/>
<size>48</size>
<use f='codebrowser/gtsam/nonlinear/LevenbergMarquardtOptimizer.cpp' l='50' c='_ZN5gtsam27LevenbergMarquardtOptimizerC1ERKNS_20NonlinearFactorGraphERKNS_6ValuesERKNS_24LevenbergMarquardtParamsE'/>
<use f='codebrowser/gtsam/nonlinear/LevenbergMarquardtOptimizer.cpp' l='59' c='_ZN5gtsam27LevenbergMarquardtOptimizerC1ERKNS_20NonlinearFactorGraphERKNS_6ValuesERKNS_8OrderingERKNS_24LevenbergMarquardtParamsE'/>
<size>48</size>
<ovr f='codebrowser/gtsam/nonlinear/NonlinearConjugateGradientOptimizer.h' l='80' c='gtsam::NonlinearConjugateGradientOptimizer'/>
<use f='codebrowser/gtsam/nonlinear/NonlinearConjugateGradientOptimizer.h' l='81'/>
<use f='codebrowser/gtsam/nonlinear/NonlinearConjugateGradientOptimizer.h' l='101'/>
<size>48</size>
