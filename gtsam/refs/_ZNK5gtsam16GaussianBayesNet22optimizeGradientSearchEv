<dec f='codebrowser/gtsam/linear/GaussianBayesNet.h' l='197' type='VectorValues gtsam::GaussianBayesNet::optimizeGradientSearch() const'/>
<doc f='codebrowser/gtsam/linear/GaussianBayesNet.h' l='172'>/**
     * Optimize along the gradient direction, with a closed-form computation to perform the line
     * search.  The gradient is computed about \f$ \delta x=0 \f$.
     *
     * This function returns \f$ \delta x \f$ that minimizes a reparametrized problem.  The error
     * function of a GaussianBayesNet is
     *
     * \f[ f(\delta x) = \frac{1}{2} |R \delta x - d|^2 = \frac{1}{2}d^T d - d^T R \delta x +
     * \frac{1}{2} \delta x^T R^T R \delta x \f]
     *
     * with gradient and Hessian
     *
     * \f[ g(\delta x) = R^T(R\delta x - d), \qquad G(\delta x) = R^T R. \f]
     *
     * This function performs the line search in the direction of the gradient evaluated at \f$ g =
     * g(\delta x = 0) \f$ with step size \f$ \alpha \f$ that minimizes \f$ f(\delta x = \alpha g)
     * \f$:
     *
     * \f[ f(\alpha) = \frac{1}{2} d^T d + g^T \delta x + \frac{1}{2} \alpha^2 g^T G g \f]
     *
     * Optimizing by setting the derivative to zero yields \f$ \hat \alpha = (-g^T g) / (g^T G g)
     * \f$.  For efficiency, this function evaluates the denominator without computing the Hessian
     * \f$ G \f$, returning
     *
     * \f[ \delta x = \hat\alpha g = \frac{-g^T g}{(R g)^T(R g)} \f] */</doc>
<def f='codebrowser/gtsam/linear/GaussianBayesNet.cpp' l='77' ll='81' type='VectorValues gtsam::GaussianBayesNet::optimizeGradientSearch() const'/>
<doc f='codebrowser/gtsam/linear/GaussianBayesNet.cpp' l='76'>/* ************************************************************************ */</doc>
<use f='codebrowser/gtsam/linear/tests/testGaussianBayesNet.cpp' l='354' u='c' c='_ZN47GaussianBayesNetComputeSteepestDescentPointTest3runER10TestResult'/>
<use f='codebrowser/gtsam/nonlinear/DoglegOptimizer.cpp' l='104' u='c' c='_ZN5gtsam15DoglegOptimizer7iterateEv'/>
<use f='codebrowser/tests/testDoglegOptimizer.cpp' l='61' u='c' c='_ZN31DoglegOptimizerComputeBlendTest3runER10TestResult'/>
<use f='codebrowser/tests/testDoglegOptimizer.cpp' l='117' u='c' c='_ZN37DoglegOptimizerComputeDoglegPointTest3runER10TestResult'/>
<use f='codebrowser/tests/testDoglegOptimizer.cpp' l='121' u='c' c='_ZN37DoglegOptimizerComputeDoglegPointTest3runER10TestResult'/>
<use f='codebrowser/tests/testDoglegOptimizer.cpp' l='122' u='c' c='_ZN37DoglegOptimizerComputeDoglegPointTest3runER10TestResult'/>
<use f='codebrowser/tests/testDoglegOptimizer.cpp' l='128' u='c' c='_ZN37DoglegOptimizerComputeDoglegPointTest3runER10TestResult'/>
<use f='codebrowser/tests/testDoglegOptimizer.cpp' l='152' u='c' c='_ZN26DoglegOptimizerIterateTest3runER10TestResult'/>
